{"cells":[{"cell_type":"markdown","metadata":{"id":"KonRRqJvqHZC"},"source":["## Sequential Data 준비"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1EA8pVnqHZG"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","# Hyperparameters\n","input_size = 5  # 입력 벡터의 크기 --> 단어(word) 5차원\n","hidden_size = 10  # 히든 상태 크기 --> 문맥의 정보 10차원\n","sequence_length = 6  # 시퀀스 길이 --> 단어의 수\n","batch_size = 3  # 배치 크기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5UAONCGqHZI","outputId":"8e79a298-cbb1-4961-a5b3-2886209a7580","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751350513183,"user_tz":-540,"elapsed":23,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([6, 3, 5])"]},"metadata":{},"execution_count":6}],"source":["# 임의의 입력 데이터 (배치 크기, 시퀀스 길이, 입력 차원) x data\n","inputs = torch.randn(sequence_length, batch_size, input_size)\n","inputs.shape # 시퀀스 길이, 배치 크기, 입력(임베딩) 차원"]},{"cell_type":"markdown","metadata":{"id":"9O5oIZaLqHZK"},"source":["## RNN 모델 사용하기 기본\n","\n","RNN 공식문서 : https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n","\n","데이터의 차원과 모델의 입출력 차원을 주의깊게 확인합시다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kYy7C4D7qHZK","outputId":"2ab2b8ef-bd71-4bfc-cd37-75891868ebde","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751350686674,"user_tz":-540,"elapsed":28,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Output shape: torch.Size([6, 3, 10])\n","Hidden shape: torch.Size([1, 3, 10])\n"]}],"source":["# RNN 모델 build\n","rnn = nn.RNN(input_size, hidden_size, batch_first=False)\n","# batch_first=False가 디폴트이므로 생략 가능\n","\n","# RNN 실행\n","# output: 모든 타임스텝에 대한 RNN의 출력\n","# hidden: 마지막 타임스텝의 히든 상태\n","output, hidden = rnn(inputs)\n","\n","print(\"Output shape:\", output.shape)  # (seq_len, batch, hidden_size)\n","print(\"Hidden shape:\", hidden.shape)  # (num_layers, batch, hidden_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AkBuQDTSqHZL","outputId":"5c9473a2-25bd-4c2d-9f83-53fea3b81d87","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751350963318,"user_tz":-540,"elapsed":53,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Output shape: torch.Size([3, 6, 10])\n","Hidden shape: torch.Size([1, 3, 10])\n"]}],"source":["# RNN 모델\n","rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n","\n","# RNN 실행\n","# output: 모든 타임스텝에 대한 RNN의 출력\n","# hidden: 마지막 타임스텝의 히든 상태\n","output, hidden = rnn(inputs.transpose(0, 1)) # 6, 3, 5 -> 3, 6, 5 (b, s, d)\n","\n","print(\"Output shape:\", output.shape)  # (batch_size, sequence_length, hidden_size)\n","print(\"Hidden shape:\", hidden.shape)  # (num_layers, batch_size, hidden_size)"]},{"cell_type":"markdown","metadata":{"id":"Npg2iy52qHZM"},"source":["### RNN 모델 학습해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3XRvPv53qHZN","outputId":"ced0a334-4b66-4bfc-bea5-5bb0778198c2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751350997579,"user_tz":-540,"elapsed":7945,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [5/20], Loss: 0.4280\n","Epoch [10/20], Loss: 0.2265\n","Epoch [15/20], Loss: 0.0801\n","Epoch [20/20], Loss: 0.0264\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Hyperparameters\n","## model parameter\n","input_size = 5 # 한단어의 차원\n","hidden_size = 10 # 모든 문장의 의미를 담은 vector 10차원\n","\n","## data parameter\n","sequence_length = 6\n","batch_size = 3\n","num_classes = 2 # 0, 1\n","\n","## training parameter\n","learning_rate = 0.01\n","num_epochs = 20\n","\n","# 간단한 RNN 분류 모델\n","# 클래스의 특징/장점\n","# 유사한, 기능을 가지는 코드들을 묶어서 관리\n","# 함수(메서드)와 변수(어트리뷰트)를 같이 묶을 수 있다.\n","# 상속을 받을 수 있다. --> 미리 만들어져 있는 코드\n","\n","class SimpleRNN(nn.Module): #객체지향, 절차형, 함수형 (데이터분석, 웹서버)\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(SimpleRNN, self).__init__()\n","        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        _, hidden = self.rnn(x)\n","        out = self.fc(hidden[0])  # 마지막 타임스텝의 출력만 사용\n","        return out\n","\n","# 모델, 손실 함수, 옵티마이저 초기화\n","model = SimpleRNN(input_size, hidden_size, num_classes)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 임의의 입력 데이터와 레이블\n","inputs = torch.randn(batch_size, sequence_length, input_size)\n","labels = torch.tensor([0, 1, 0]) # 3개의 레이블 : BATCHSIZE = 3\n","\n","# 학습\n","for epoch in range(num_epochs):\n","    outputs = model(inputs)\n","    loss = criterion(outputs, labels)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 5 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"]},{"cell_type":"markdown","metadata":{"id":"ABnU-M-uqHZO"},"source":["### multi layer RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DAaVl0IiqHZP","outputId":"8afc974a-3da5-4cad-ab4f-b6c2bcc391fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape: torch.Size([3, 6, 10])\n","Hidden shape: torch.Size([4, 3, 10])\n"]}],"source":["num_layers = 4\n","rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n","outputs, hidden = rnn(inputs) # inputs: (batch_size, seq_length, input_size)\n","print(\"Output shape:\", outputs.shape) # (batch_size, seq_length, hidden_size)\n","print(\"Hidden shape:\", hidden.shape) # (num_layers, batch_size, hidden_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lD6TSC4DqHZP","outputId":"e20e2d88-ee66-4f14-f651-b859c780c719"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [5/20], Loss: 0.5117\n","Epoch [10/20], Loss: 0.1344\n","Epoch [15/20], Loss: 0.0332\n","Epoch [20/20], Loss: 0.0134\n"]}],"source":["class MultiLayerRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(MultiLayerRNN, self).__init__()\n","        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        out, _ = self.rnn(x)\n","        out = self.fc(out[:, -1, :]) #batch, seq, hidden\n","        return out\n","\n","num_layers = 4\n","model = MultiLayerRNN(input_size, hidden_size, num_layers, num_classes)\n","\n","# 모델, 손실 함수, 옵티마이저 초기화\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 임의의 입력 데이터와 레이블\n","inputs = torch.randn(batch_size, sequence_length, input_size)\n","labels = torch.tensor([0, 1, 0])\n","\n","# 학습\n","for epoch in range(num_epochs):\n","    outputs = model(inputs)\n","    loss = criterion(outputs, labels)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 5 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"]},{"cell_type":"markdown","metadata":{"id":"El5fx8KuqHZQ"},"source":["### 양방향 RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQoW7dAOqHZQ","outputId":"c701a213-520d-439a-efad-44fb3ade70ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape: torch.Size([3, 6, 20])\n","Hidden shape: torch.Size([8, 3, 10])\n"]}],"source":["rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","outputs, hidden = rnn(inputs)\n","\n","# input_size = 5\n","# hidden_size = 10\n","# sequence_length = 6\n","# batch_size = 3\n","# num_layers = 4\n","print(\"Output shape:\", outputs.shape) # (batch_size, seq_length, hidden_size * 2)\n","print(\"Hidden shape:\", hidden.shape) # (num_layers * 2, batch_size, hidden_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Tlf5q6qqHZR"},"outputs":[],"source":["# RNN의 hidden은 첫번째 레이어부터 마지막 레이어까지 forward, backward가 순차적으로 쌓인 것\n","out_forward = outputs[:, -1, :hidden_size]  # forward 방향의 마지막 타임스텝 출력\n","out_backward = outputs[:, 0, hidden_size:]  # backward 방향의 첫 번째 타임스텝 출력 (뒤에서 앞으로)\n","\n","# forward와 backward 방향의 출력을 결합\n","out_combined = torch.cat((out_forward, out_backward), dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRpmQeybqHZT"},"outputs":[],"source":["# 또는 hidden을 이용할 수도 있음\n","#https://stackoverflow.com/questions/63121983/bidirectional-rnn-implementation-pytorch\n","out_combined = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9Easu4ZqHZT","outputId":"5534470a-e52f-4330-b7d0-57345649500a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751352418230,"user_tz":-540,"elapsed":125,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [5/20], Loss: 0.3456\n","Epoch [10/20], Loss: 0.0788\n","Epoch [15/20], Loss: 0.0184\n","Epoch [20/20], Loss: 0.0057\n"]}],"source":["class BiDirectionalRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(BiDirectionalRNN, self).__init__()\n","        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size * 2, num_classes)  # 양방향이므로 Linear에 넣어야 하는 히든 크기가 2배\n","\n","    def forward(self, x):\n","        out, hidden = self.rnn(x)\n","\n","        # hidden[-2,:,:]: forward의 마지막 레이어 마지막 타임스텝 히든 상태\n","        # hidden[-1,:,:]: backward의 마지막 레이어 마지막 타임스텝 히든 상태\n","        out_combined = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)  # 마지막 타임스텝의 출력만 사용\n","        out = self.fc(out_combined)\n","        return out\n","\n","# 모델 초기화 (양방향 설정)\n","model = BiDirectionalRNN(input_size, hidden_size, num_layers=2, num_classes=num_classes)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 임의의 입력 데이터와 레이블\n","inputs = torch.randn(batch_size, sequence_length, input_size)\n","labels = torch.tensor([0, 1, 0])\n","\n","# 학습\n","for epoch in range(num_epochs):\n","    outputs = model(inputs)\n","    loss = criterion(outputs, labels)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 5 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xnDhwN8OqHZU"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"torch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}