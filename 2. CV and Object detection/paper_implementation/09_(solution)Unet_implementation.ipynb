{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPGOB67xgjSf3FI7xlpzTmk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Unet Implementation"],"metadata":{"id":"fgi6oB-qC2H5"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"gwMMkrZr9PVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DoubleConv(nn.Module):\n","    \"\"\"\n","    A double convolution block\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.double_conv = nn.Sequential(\n","            # 1st conv layer\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            # 2nd conv layer\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)"],"metadata":{"id":"E01i3-ET9WY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# center_crop (피처 , [h, w])\n","F.center_crop()"],"metadata":{"id":"xj_LSFnlDCCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WUjddV-X9L4d"},"outputs":[],"source":["class UNet(nn.Module):\n","    \"\"\"\n","    U-Net implementation\n","    1. encoder (contracting path)\n","    2. decoder (expansive path)\n","    3. skip connections\n","    \"\"\"\n","    def __init__(self, in_channels=3, out_channels=1, init_features=64):\n","        super(UNet, self).__init__()\n","\n","        features = init_features\n","\n","        # Contracting path (Encoder)\n","        self.encoder1 = DoubleConv(in_channels, features)\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.encoder2 = DoubleConv(features, features*2)\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.encoder3 = DoubleConv(features*2, features*4)\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.encoder4 = DoubleConv(features*4, features*8)\n","        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # bottleneck between enc & dec\n","        self.bottleneck = DoubleConv(features*8, features*16)\n","\n","        # Expanding path (Decoder)\n","        self.upconv4 = nn.ConvTranspose2d(\n","            features*16, features*8, kernel_size=4, stride=2) # kernel_size=2로 가도 된다.(메모리 효율)\n","        self.decoder4 = DoubleConv(features*16, features*8)\n","\n","        self.upconv3 = nn.ConvTranspose2d(\n","            features*8, features*4, kernel_size=4, stride=2\n","        )\n","        self.decoder3 = DoubleConv(features*8, features*4)\n","\n","        self.upconv2 = nn.ConvTranspose2d(\n","            features*4, features*2, kernel_size=4, stride=2\n","        )\n","        self.decoder2 = DoubleConv(features * 4, features * 2)\n","\n","        self.upconv1 = nn.ConvTranspose2d(\n","            features*2, features, kernel_size=4, stride=2\n","        )\n","        self.decoder1 = DoubleConv(features*2, features)\n","\n","        # Final convolution to map to desired number of classes\n","        self.final_conv = nn.Conv2d(features, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        # Contracting path (Encoder)\n","        enc1 = self.encoder1(x)\n","        enc2 = self.encoder2(self.pool1(enc1))\n","        enc3 = self.encoder3(self.pool2(enc2))\n","        enc4 = self.encoder4(self.pool3(enc3))\n","\n","        # bottleneck between enc & dec\n","        bottleneck = self.bottleneck(self.pool4(enc4))\n","\n","        # Expanding path (Decoder)\n","        # 업샘플링 -> center crop -> concatenate -> double conv\n","        dec4 = self.upconv4(bottleneck)\n","        cropped_enc4 = F.center_crop(enc4, dec4.shape[2:]) # center_crop (피처 , [h, w])\n","        dec4 = self.decoder4(torch.cat([dec4, cropped_enc4], dim=1))\n","\n","        dec3 = self.upconv3(dec4)\n","        cropped_enc3 = F.center_crop(enc3, dec3.shape[2:])\n","        dec3 = self.decoder3(torch.cat([dec3, cropped_enc3], dim=1))\n","\n","        dec2 = self.upconv2(dec3)\n","        cropped_enc2 = F.center_crop(enc2, dec2.shape[2:])\n","        dec2 = self.decoder2(torch.cat([dec2, cropped_enc2], dim=1))\n","\n","        dec1 = self.upconv1(dec2)\n","        cropped_enc1 = F.center_crop(enc1, dec1.shape[2:])\n","        dec1 = self.decoder1(torch.cat([dec1, cropped_enc1], dim=1))\n","\n","        return self.final_conv(dec1)"]},{"cell_type":"markdown","source":["## 직접 해보기\n","패딩을 주는 방식으로 unet을 설계해보자.(어떤 차이가 있을지 유념하자!)"],"metadata":{"id":"eTeYoodU1zmw"}},{"cell_type":"code","source":[],"metadata":{"id":"j7OAd7ur1zXI"},"execution_count":null,"outputs":[]}]}