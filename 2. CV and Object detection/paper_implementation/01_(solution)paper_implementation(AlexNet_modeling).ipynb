{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# pytorch 기반 alexnet 구현"],"metadata":{"id":"knwTvYOg6LMy"}},{"cell_type":"code","source":["im port torch\n","import torch.nn as nn\n","\n","class AlexNet(nn.Module):\n","    def __init__(self, num_classes=1000):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n","            nn.ReLU(),\n","            nn.LocalResponseNorm(5),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","\n","            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n","            nn.ReLU(),\n","            nn.LocalResponseNorm(5),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","\n","            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2)\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, num_classes) #파이토치의 규칙 때문에 Linear로 마무리, Cross Entropy Loss에서 계산\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1) # == flatten()\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"iBGDOSQ-6Np5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AlexNet(num_classes=10)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YykCYtNm6WMN","executionInfo":{"status":"ok","timestamp":1716510756205,"user_tz":-540,"elapsed":1939,"user":{"displayName":"wonjae lee","userId":"02946067935890729436"}},"outputId":"d713a11c-c423-43f5-ff2b-043a9cd889f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU()\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU()\n","    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU()\n","    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU()\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=9216, out_features=4096, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU()\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["# AlexNet 모델을 간소화해봅시다\n","## resize없이 (28, 28, 3)으로 받아봅시다\n","\n","## ** activation 은 모두 relu로 유지\n","## normalizing 유지\n","## pooling은 (2, 2) overlapping x\n","\n","## layer 1 : 32개, (3, 3), strides=1\n","## layer 2 : 64개, (3, 3), strides=1\n","## layer 3 : 128개, (3, 3), strides=1\n","\n","## layer 4, 5 : 삭제\n","\n","## fully connected layer 1, 2 : node 원하는대로 주기\n"],"metadata":{"id":"tmSTegjzon0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train():\n","   # 디바이스 설정\n","   device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","   # 모델 생성\n","   model = AlexNet(num_classes=10).to(device)\n","\n","   # Loss function과 optimizer 정의\n","   criterion = nn.CrossEntropyLoss()\n","   optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","   # 데이터 로더 예시 (실제로는 여기에 데이터셋 로딩 코드 필요)\n","   # train_loader = ...\n","\n","   # 학습 루프\n","   num_epochs = 90\n","   for epoch in range(num_epochs):\n","       model.train()\n","       running_loss = 0.0\n","\n","       for inputs, labels in train_loader:\n","           inputs, labels = inputs.to(device), labels.to(device)\n","\n","           # gradient 초기화\n","           optimizer.zero_grad()\n","\n","           # forward + backward + optimize\n","           outputs = model(inputs)\n","           loss = criterion(outputs, labels)\n","           loss.backward()\n","           optimizer.step()\n","\n","           running_loss += loss.item()\n","\n","       print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')"],"metadata":{"id":"vKdnI3kZx4pI"},"execution_count":null,"outputs":[]}]}