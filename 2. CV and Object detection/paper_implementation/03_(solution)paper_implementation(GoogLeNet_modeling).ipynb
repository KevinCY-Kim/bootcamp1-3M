{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Pytorch 기반 GoogLeNet 구현\n"],"metadata":{"id":"J3tosh9cEm4U"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"J4qWdO03MECd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### inception module class"],"metadata":{"id":"dXKfZU2_MH1d"}},{"cell_type":"code","source":["class InceptionBlock(nn.Module):\n","   def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n","       super(InceptionBlock, self).__init__()\n","\n","       # 1x1 convolution branch\n","       self.branch1 = nn.Sequential(\n","           nn.Conv2d(in_channels, ch1x1, kernel_size=1),\n","           nn.ReLU(inplace=True) # inplace 위의 Conv2d의 결과 값을 덮어쓰기\n","       )\n","\n","       # 1x1 convolution -> 3x3 convolution branch\n","       self.branch2 = nn.Sequential(\n","           nn.Conv2d(in_channels, ch3x3red, kernel_size=1),\n","           nn.ReLU(inplace=True),\n","           nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, padding=1),\n","           nn.ReLU(inplace=True)\n","       )\n","\n","       # 1x1 convolution -> 5x5 convolution branch\n","       self.branch3 = nn.Sequential(\n","           nn.Conv2d(in_channels, ch5x5red, kernel_size=1),\n","           nn.ReLU(inplace=True),\n","           nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, padding=2),\n","           nn.ReLU(inplace=True)\n","       )\n","\n","       # 3x3 max pooling -> 1x1 convolution branch\n","       self.branch4 = nn.Sequential(\n","           nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","           nn.Conv2d(in_channels, pool_proj, kernel_size=1),\n","           nn.ReLU(inplace=True)\n","       )\n","\n","   def forward(self, x):\n","       branch1 = self.branch1(x)\n","       branch2 = self.branch2(x)\n","       branch3 = self.branch3(x)\n","       branch4 = self.branch4(x)\n","\n","       # Concatenate along the channel dimension\n","       outputs = [branch1, branch2, branch3, branch4]\n","       return torch.cat(outputs, 1) # 1 == c / b, c, h, w"],"metadata":{"id":"iUtBNXFVMDot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Auxilary classifier class"],"metadata":{"id":"UZwjmN3tMNka"}},{"cell_type":"code","source":["class AuxiliaryClassifier(nn.Module):\n","   def __init__(self, in_channels, num_classes):\n","       super(AuxiliaryClassifier, self).__init__()\n","\n","       self.avgpool = nn.AvgPool2d(kernel_size=5, stride=3)\n","       self.conv = nn.Conv2d(in_channels, 128, kernel_size=1)\n","       self.relu = nn.ReLU(inplace=True)\n","       self.fc1 = nn.Linear(2048, 1024)\n","       self.dropout = nn.Dropout(p=0.7)\n","       self.fc2 = nn.Linear(1024, num_classes)\n","\n","   def forward(self, x):\n","       x = self.avgpool(x)\n","       x = self.conv(x)\n","       x = self.relu(x)\n","       x = torch.flatten(x, 1)\n","       x = self.fc1(x)\n","       x = self.relu(x)\n","       x = self.dropout(x)\n","       x = self.fc2(x)\n","       return x"],"metadata":{"id":"ob1Ne6VKMBKS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### main modeling class"],"metadata":{"id":"2rpo7p8SMSfC"}},{"cell_type":"code","source":["def train():\n","   device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","   model = GoogLeNet(num_classes=1000, aux_logits=True).to(device)\n","\n","   # Loss and optimizer\n","   criterion = nn.CrossEntropyLoss()\n","   optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","   # Training loop\n","   model.train()\n","   for epoch in range(num_epochs):\n","       for inputs, labels in train_loader:\n","           inputs = inputs.to(device)\n","           labels = labels.to(device)\n","\n","           # Forward pass\n","           if model.aux_logits:\n","               outputs, aux1, aux2 = model(inputs)\n","               loss1 = criterion(outputs, labels)\n","               loss2 = criterion(aux1, labels)\n","               loss3 = criterion(aux2, labels)\n","               loss = loss1 + 0.3*(loss2 + loss3)\n","           else:\n","               outputs = model(inputs)\n","               loss = criterion(outputs, labels)\n","\n","           # Backward and optimize\n","           optimizer.zero_grad()\n","           loss.backward()\n","           optimizer.step()"],"metadata":{"id":"A6UrLYJQMXb6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GoogLeNet(nn.Module):\n","   def __init__(self, num_classes=1000, aux_logits=True):\n","       super(GoogLeNet, self).__init__()\n","\n","       self.aux_log its = aux_logits\n","\n","       # Initial layers\n","       self.conv1 = nn.Sequential(\n","           nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n","           nn.ReLU(inplace=True),\n","           nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","       )\n","\n","       self.conv2 = nn.Sequential(\n","           nn.Conv2d(64, 64, kernel_size=1),\n","           nn.ReLU(inplace=True),\n","           nn.Conv2d(64, 192, kernel_size=3, padding=1),\n","           nn.ReLU(inplace=True),\n","           nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","       )\n","\n","       # Inception blocks\n","       self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n","       self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n","       self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","       self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n","       self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n","       self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n","       self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n","       self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n","       self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","       self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n","       self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n","\n","       # Auxiliary classifiers\n","       if self.aux_logits:\n","           self.aux1 = AuxiliaryClassifier(512, num_classes)\n","           self.aux2 = AuxiliaryClassifier(528, num_classes)\n","\n","       # Final layers\n","       self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","       self.dropout = nn.Dropout(0.4)\n","       self.fc = nn.Linear(1024, num_classes)\n","\n","       # Weight initialization\n","       self._initialize_weights()\n","\n","   def forward(self, x):\n","       # N x 3 x 224 x 224\n","       x = self.conv1(x)\n","       # N x 64 x 112 x 112\n","       x = self.conv2(x)\n","       # N x 192 x 56 x 56\n","       x = self.inception3a(x)\n","       # N x 256 x 56 x 56\n","       x = self.inception3b(x)\n","       # N x 480 x 56 x 56\n","       x = self.maxpool3(x)\n","       # N x 480 x 28 x 28\n","       x = self.inception4a(x)\n","       # N x 512 x 28 x 28\n","\n","       if self.training and self.aux_logits:\n","           aux1 = self.aux1(x)\n","\n","       x = self.inception4b(x)\n","       x = self.inception4c(x)\n","       x = self.inception4d(x)\n","\n","       if self.training and self.aux_logits:\n","           aux2 = self.aux2(x)\n","\n","       x = self.inception4e(x)\n","       x = self.maxpool4(x)\n","       x = self.inception5a(x)\n","       x = self.inception5b(x)\n","\n","       x = self.avgpool(x)\n","       x = torch.flatten(x, 1)\n","       x = self.dropout(x)\n","       x = self.fc(x)\n","\n","       if self.training and self.aux_logits:\n","           return x, aux1, aux2\n","       return x\n","\n","   def _initialize_weights(self):\n","       for m in self.modules():\n","           if isinstance(m, nn.Conv2d):\n","               nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","               if m.bias is not None:\n","                   nn.init.constant_(m.bias, 0)\n","           elif isinstance(m, nn.Linear):\n","               nn.init.normal_(m.weight, 0, 0.01)\n","               nn.init.constant_(m.bias, 0)"],"metadata":{"id":"vMXsJWH5L8Em"},"execution_count":null,"outputs":[]}]}