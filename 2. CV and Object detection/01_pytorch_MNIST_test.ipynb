{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BJ4LcAssuNVL"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","source":["# 배치 크기 × 채널 × 높이(height) × 너비(widht)의 크기의 텐서를 선언\n","inputs = torch.Tensor(1, 1, 28, 28)\n","print('텐서의 크기 : {}'.format(inputs.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j98PVl47uP7e","outputId":"b063e478-559e-4ef6-e2af-0deea1e47bc5","executionInfo":{"status":"ok","timestamp":1748484129563,"user_tz":-540,"elapsed":12,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["텐서의 크기 : torch.Size([1, 1, 28, 28])\n"]}]},{"cell_type":"code","source":["inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"moQNCtMHxtSL","executionInfo":{"status":"ok","timestamp":1748484156695,"user_tz":-540,"elapsed":143,"user":{"displayName":"김창용","userId":"08165353884628186490"}},"outputId":"d121457c-c16b-4361-cbd5-5a52cc329d80"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[-1.7164e+17,  4.4627e-41, -1.7164e+17,  4.4627e-41,  4.7354e-06,\n","            0.0000e+00,  4.7354e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00, -5.5156e+24,  4.4626e-41],\n","          [-5.5156e+24,  4.4626e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4013e-45,\n","                   nan,         nan,         nan],\n","          [        nan,  1.4013e-45,  1.0293e-41,  0.0000e+00, -1.7162e+17,\n","            4.4627e-41, -1.7162e+17,  4.4627e-41,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4153e-43,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            2.8026e-45,  2.8026e-45,  1.2612e-44,  1.9618e-44,  2.2421e-43,\n","            1.4013e-45,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  2.8026e-45,  2.8026e-45,  1.2612e-44,\n","            2.9427e-44,  1.4013e-43,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  2.8026e-45,  2.8026e-45,  3.0829e-44,\n","            3.2230e-44,  1.4013e-43,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  2.8026e-45,  2.8026e-45,  3.5032e-44,\n","            3.6434e-44,  1.4013e-43,  1.4013e-45],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8026e-45,\n","            2.8026e-45,  3.9236e-44,  4.2039e-44,  1.4013e-43,  1.4013e-45,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8026e-45,\n","            2.8026e-45,  4.4842e-44,  4.7644e-44,  2.3262e-43,  5.6052e-45,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8026e-45,\n","            2.8026e-45,  1.2612e-44,  4.9045e-44],\n","          [ 2.3962e-43,  5.6052e-45,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  2.8026e-45,  2.8026e-45,  1.2612e-44,  4.9045e-44,\n","            1.2612e-43,  2.8026e-45,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  2.8026e-45,  2.8026e-45,  0.0000e+00,  8.4078e-45,\n","            1.4013e-43,  2.8026e-45,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  2.8026e-45,  2.8026e-45],\n","          [ 0.0000e+00,  8.4078e-45,  1.1631e-43,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8026e-45,  2.8026e-45,\n","            0.0000e+00,  8.4078e-45,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  9.3733e-42,  0.0000e+00],\n","          [-1.7162e+17,  4.4627e-41, -1.7162e+17,  4.4627e-41,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  4.2039e-45,  4.2039e-45,  8.4078e-45,\n","            7.0065e-44,  2.3262e-43,  7.0065e-45,  5.0447e-44,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  4.2039e-45,  4.2039e-45,  0.0000e+00,\n","            7.1466e-44,  2.3962e-43,  1.4013e-45],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.2039e-45,\n","            4.2039e-45,  0.0000e+00,  7.1466e-44,  1.4013e-45,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.2039e-45,\n","            4.2039e-45,  0.0000e+00,  7.1466e-44,  1.4013e-43,  4.2039e-45,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.2039e-45,\n","            4.2039e-45,  0.0000e+00,  7.1466e-44],\n","          [ 1.1631e-43,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  4.2039e-45,  4.2039e-45,  0.0000e+00,  7.1466e-44,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  8.4765e-42,  0.0000e+00,\n","           -1.7162e+17,  4.4627e-41, -1.7162e+17,  4.4627e-41,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","           -1.0310e+16,  4.4627e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00, -5.1429e+11,  4.4627e-41,  0.0000e+00,\n","            4.4626e-41,  2.1352e-17,  5.5539e-15],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00, -5.6765e+24,  4.4626e-41,\n","           -1.6421e-23, -3.3971e-02, -5.6130e+24,  4.4626e-41, -1.3214e-32,\n","           -2.1379e-17, -5.5733e+24,  4.4626e-41,  2.7729e-17,  6.4084e-22,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            7.8935e-42,  0.0000e+00, -1.7162e+17,  4.4627e-41, -1.7162e+17,\n","            4.4627e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.4532e+24,\n","            4.4626e-41, -1.2351e-29, -1.0567e+17, -5.5297e+24,  4.4626e-41,\n","           -5.1080e+16, -4.8602e-14,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","           -5.6783e+24,  4.4626e-41,  2.2051e+00,  2.1332e+04,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 2.8026e-45,  0.0000e+00, -2.6154e+15,  4.4627e-41,  0.0000e+00,\n","            0.0000e+00, -2.6131e+15,  4.4627e-41,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  2.8026e-45,  0.0000e+00, -2.6154e+15,\n","            4.4627e-41,  0.0000e+00,  4.4627e-41, -7.5405e+24,  4.4626e-41,\n","           -7.5405e+24,  4.4626e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [-7.5405e+24,  4.4626e-41, -7.5405e+24,  4.4626e-41,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            1.4013e-45,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4003e-42,\n","            0.0000e+00, -1.7162e+17,  4.4627e-41, -1.7162e+17,  4.4627e-41,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [-5.4896e+24,  4.4626e-41, -4.1474e+10, -7.0027e+23, -5.6486e+24,\n","            4.4626e-41,  1.3686e-09, -1.5477e+20,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00, -5.5607e+24,  4.4626e-41, -2.3853e+00, -3.4205e-38,\n","           -5.7283e+24,  4.4626e-41,  1.5932e+15,  2.9777e+31,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.6215e+24,\n","            4.4626e-41,  4.2539e+17, -8.4336e-20, -5.4437e+24,  4.4626e-41,\n","            2.3794e+31,  1.0656e+21,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","           -5.6828e+24,  4.4626e-41, -9.3314e-40,  4.8583e+35,  0.0000e+00,\n","            0.0000e+00,  0.0000e+00,  0.0000e+00]]]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["conv1 = nn.Conv2d(1, 32, 3, padding=1) # 필터의 채널(=in_channel), 개수(out_channel), 크기\n","print(conv1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xaJG115buRjN","outputId":"8e72c7ac-35da-4bd3-9915-b9accd4056ab","executionInfo":{"status":"ok","timestamp":1748484352849,"user_tz":-540,"elapsed":48,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"]}]},{"cell_type":"code","source":["conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","print(conv2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHLj03TyuUGb","outputId":"6d465909-b1e6-43c2-8060-7b3bd93de67f","executionInfo":{"status":"ok","timestamp":1748484691579,"user_tz":-540,"elapsed":53,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"]}]},{"cell_type":"code","source":["pool = nn.MaxPool2d(2)\n","print(pool)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zoFQFO1huWFQ","outputId":"3178c376-cfda-428c-bd8e-b5aa281f47df","executionInfo":{"status":"ok","timestamp":1748484693431,"user_tz":-540,"elapsed":21,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"]}]},{"cell_type":"markdown","source":["지금까지는 선언만한 것이고 아직 이들을 연결시키지는 않았습니다. 이들을 연결시켜서 모델을 완성시켜보겠습니다. 우선 입력을 첫번째 합성곱층을 통과시키고 합성곱층을 통과시킨 후의 텐서의 크기를 보겠습니다."],"metadata":{"id":"Ine1CWGwubhT"}},{"cell_type":"code","source":["out = conv1(inputs)\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1slraBJzuXpk","outputId":"870db763-266d-48c2-9619-0f62b492e3cc","executionInfo":{"status":"ok","timestamp":1748484706873,"user_tz":-540,"elapsed":45,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 32, 28, 28])\n"]}]},{"cell_type":"code","source":["out = pool(out)\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBRE6gyFuZek","outputId":"26d3b36d-5351-441b-b38a-8750d040da94","executionInfo":{"status":"ok","timestamp":1748484708364,"user_tz":-540,"elapsed":8,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 32, 14, 14])\n"]}]},{"cell_type":"code","source":["out = conv2(out)\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvyLe9Ewuduo","outputId":"2aa26029-5c94-462d-e469-76d04309acfd","executionInfo":{"status":"ok","timestamp":1748484714401,"user_tz":-540,"elapsed":8,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 64, 14, 14])\n"]}]},{"cell_type":"code","source":["out = pool(out)\n","print(out.shape) # batch, c, h, w -> batch, cxhxw"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TsT8SdmfufB2","outputId":"d69f743c-d48f-4c67-cade-af657d4b4943","executionInfo":{"status":"ok","timestamp":1748484726818,"user_tz":-540,"elapsed":17,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 64, 7, 7])\n"]}]},{"cell_type":"code","source":["# 첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼쳐라\n","out = out.view(out.size(0), -1) # (0)은 out\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7IpPmZfugKK","outputId":"fae187c1-32dc-4319-c819-93b86183ee59","executionInfo":{"status":"ok","timestamp":1748486624037,"user_tz":-540,"elapsed":9,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 3136])\n"]}]},{"cell_type":"code","source":["fc = nn.Linear(3136, 10) # input_dim = 3,136, output_dim = 10\n","out = fc(out)\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0RqOcWwunIN","outputId":"c360a985-ff80-418c-c943-e41c939d0bcb","executionInfo":{"status":"ok","timestamp":1748486625441,"user_tz":-540,"elapsed":28,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 10])\n"]}]},{"cell_type":"markdown","source":["## CNN으로 MNIST 분류하기"],"metadata":{"id":"pVEh08xIuofR"}},{"cell_type":"code","source":["import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init"],"metadata":{"id":"_h1sZPsfuspH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 랜덤 시드 고정 : 고정된 무작위성\n","torch.manual_seed(777)\n","\n","# GPU 사용 가능일 경우 랜덤 시드 고정\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)"],"metadata":{"id":"dy2_fiTDutva"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 256"],"metadata":{"id":"u-5mOAlQuvvz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n","                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n","                          transform=transforms.ToTensor(), # 텐서로 변환\n","                          download=True)\n","\n","mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n","                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n","                         transform=transforms.ToTensor(), # 텐서로 변환\n","                         download=True)"],"metadata":{"id":"ZuptDOgduw-r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n","                                          batch_size=batch_size,\n","                                          shuffle=True,\n","                                          drop_last=True)"],"metadata":{"id":"EKjOVxDyuyc0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNN(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # 첫번째층\n","        # ImgIn shape=(?, 1, 28, 28)\n","        #    Conv     -> (?, 32, 28, 28)\n","        #    Pool     -> (?, 32, 14, 14)\n","        self.layer1 = torch.nn.Sequential(\n","            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # 두번째층\n","        # ImgIn shape=(?, 32, 14, 14)\n","        #    Conv      ->(?, 64, 14, 14)\n","        #    Pool      ->(?, 64, 7, 7)\n","        self.layer2 = torch.nn.Sequential(\n","            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # 전결합층 7x7x64 inputs -> 10 outputs\n","        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n","        out = self.fc(out)\n","        return out"],"metadata":{"id":"9OjnULsIu1dr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN 모델 정의\n","model = CNN().to(device) # .to('cuda') == .cuda() / .to('cpu') == .cpu()"],"metadata":{"id":"h39wXiBPu4Q7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Loss\n","- pytorch에서는 CrossEntropyLoss()로 sparse categorical, categorical 두개를 자동으로 인식하여 처리한다. (softmax 포함하기 때문에 모델에서 Softmax 생략)\n","- 이진분류 경우에는 BCELoss() 사용 (sigmoid 미포함이므로 모델에서 sigmoid 선언)"],"metadata":{"id":"RDejqCN7jQBq"}},{"cell_type":"code","source":["criterion = torch.nn.CrossEntropyLoss()   # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"YJwvKLdcu5g-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_batch = len(data_loader)\n","print('총 배치의 수 : {}'.format(total_batch))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lea4TRDBu7rT","outputId":"5dfa12c5-68a3-45b7-9025-2e9dd48ca482","executionInfo":{"status":"ok","timestamp":1748491431338,"user_tz":-540,"elapsed":13,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["총 배치의 수 : 234\n"]}]},{"cell_type":"code","source":["for epoch in range(training_epochs):\n","    avg_cost = 0\n","\n","    for X, Y in data_loader:\n","        X = X.to(device)\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = model(X) # forward 실행\n","        cost = criterion(hypothesis, Y) # CrossEntropyLoss\n","        cost.backward() # gradient 계산\n","        optimizer.step() # weight 업데이트\n","\n","        avg_cost += cost / total_batch\n","\n","    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUo3rX1ku85T","outputId":"18446cb5-28b2-4830-c18a-072d87bed058","executionInfo":{"status":"ok","timestamp":1748491525801,"user_tz":-540,"elapsed":92761,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch:    1] cost = 0.361124814\n","[Epoch:    2] cost = 0.0858989954\n","[Epoch:    3] cost = 0.0583948568\n","[Epoch:    4] cost = 0.0486581624\n","[Epoch:    5] cost = 0.0413193703\n","[Epoch:    6] cost = 0.035832379\n","[Epoch:    7] cost = 0.0311829783\n","[Epoch:    8] cost = 0.0282983985\n","[Epoch:    9] cost = 0.0259521101\n","[Epoch:   10] cost = 0.0237825681\n","[Epoch:   11] cost = 0.0200017188\n","[Epoch:   12] cost = 0.018089911\n","[Epoch:   13] cost = 0.0176163223\n","[Epoch:   14] cost = 0.0156986602\n","[Epoch:   15] cost = 0.0137931211\n"]}]},{"cell_type":"code","source":["with torch.no_grad():\n","    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n","    Y_test = mnist_test.test_labels.to(device)\n","\n","    prediction = model(X_test)\n","    correct_prediction = torch.argmax(prediction, 1) == Y_test\n","    accuracy = correct_prediction.float().mean()\n","    print('Accuracy:', accuracy.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFcOYB4Iu_Gf","outputId":"e82bb32b-a80b-4ed8-8b18-8ed0b7db920f","executionInfo":{"status":"ok","timestamp":1748491538281,"user_tz":-540,"elapsed":84,"user":{"displayName":"김창용","userId":"08165353884628186490"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9835000038146973\n"]}]},{"cell_type":"markdown","source":["## 깊은 CNN으로 MNIST 분류하기"],"metadata":{"id":"I73AbLS0vIAj"}},{"cell_type":"markdown","source":["직접 해봅시다.\n","\n","위 코드를 참고하여, 더 깊은 CNN 레이어를 쌓아보고, 학습시켜봅시다."],"metadata":{"id":"ziHIm9tZvkPE"}},{"cell_type":"code","source":[],"metadata":{"id":"6GC-BWhhdqQt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 정답"],"metadata":{"id":"4ETMZyC4dxef"}},{"cell_type":"code","source":["\n","class CNN(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.layer1 = torch.nn.Sequential(\n","            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        self.layer2 = torch.nn.Sequential(\n","            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        self.layer3 = torch.nn.Sequential(\n","            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n","\n","        # 전결합층 한정으로 가중치 초기화\n","        torch.nn.init.xavier_uniform_(self.fc.weight)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out"],"metadata":{"id":"CAKC43Ed9hzA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = CNN().cuda() # to('cuda')\n","\n","criterion = torch.nn.CrossEntropyLoss().to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"O9O0kq5mskzz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(training_epochs):\n","    for X, Y in data_loader:\n","        X = X.to(device)\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = model(X)\n","        cost = criterion(hypothesis, Y)\n","        cost.backward()\n","        optimizer.step()"],"metadata":{"id":"hLnnhrbss2mT","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1748491722548,"user_tz":-540,"elapsed":175,"user":{"displayName":"김창용","userId":"08165353884628186490"}},"outputId":"773cdc7a-4716-468b-eddd-2d5bd4feee3e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (256x1152 and 3136x10)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-4e442972384c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-53775f91c857>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x1152 and 3136x10)"]}]}]}